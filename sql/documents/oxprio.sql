insert into documents(url,title,publication_date,modified_date,author,publisher,affected_donors,affected_donees,document_scope,cause_area,notes) values
  ('https://oxpr.io/blog/2017/3/11/qays-langan-dathi-ai-safety','AI Safety: Is it worthwhile for us to look further into donating into AI research?','2017-03-11',NULL',Qays Langan-Dathi','Oxford Prioritisation Project','Oxford Prioritisation Project','Machine Intelligence Research Institute','Review of current state of cause area','AI risk','The post concludes: "In conclusion my answer to my main point is, yes. There is a good chance that AI risk prevention is the most cost effective focus area for saving the most amount of lives with or without regarding future human lives."'),
  ('https://oxpr.io/blog/2017/3/11/daniel-may-should-we-make-a-grant-to-a-meta-charity','Should we make a grant to a meta-charity?','2017-03-11',NULL,'Daniel May','Oxford Prioritisation Project','Oxford Prioritisation Project','Giving What We Can,80000 Hours,Raising for Effective Giving','Review of current state of cause area','Effective altruism/movement growth/fundraising','The summary says: "I introduce the concept of meta-charity, discuss some considerations for OxPrio, and look into how meta-charities evaluate their impact, and the reliability of these figures for our purposes (finding the most cost-effective organisation to donate £10,000 today). I then look into the room for more funding for a few meta-charities, and finally conclude that these are worth seriously pursuing further." See http://effective-altruism.com/ea/189/daniel_may_should_we_make_a_grant_to_a/ for a cross-post that has comments'),
  ('https://oxpr.io/blog/2017/4/19/modelling-the-good-food-institute','Modelling the Good Food Institute','2017-04-18',NULL,'Dominik Peters','Oxford Prioritisation Project','Oxford Prioritisation Project','The Good Food Institute','Evaluator review of donee','Animal welfare/meat alternatives','The summary says: "We have attempted to build a quantitative model to estimate the impact of the Good Food Institute (GFI). We have found this exceptionally difficult due to the diversity of GFI’s activities and the particularly unclear counterfactuals. In this post, I explain some of the modelling approaches we tried, and why we are not satisfied with them."'),
  ('https://oxpr.io/blog/2017/4/25/charity-evaluators-a-first-model-and-open-questions','Charity evaluators: a first model and open questions','2017-04-25',NULL,'Dominik Peters,Tom Sittler','Oxford Prioritisation Project','Oxford Prioritisation Project','GiveWell,Animal Charity Evaluators','Review of current state of cause area','Charity evaluator','The abstract says: "We describe a simple simulation model for the recommendations of a charity evaluator like GiveWell or ACE. The model captures some real-world phenomena, such as initial overconfidence in impact estimates. We are unsure how to choose the parameters of the underlying distributions, and are happy to receive feedback on this." See http://effective-altruism.com/ea/19g/charity_evaluators_first_model_and_open_questions/ for a cross-post with comments'),
  ('https://oxpr.io/blog/2017/2/28/final-donation-decision-version-0','Final decision: Version 0','2017-03-01',NULL,'Tom Sittler','Oxford Prioritisation Project','Oxford Prioritisation Project','Against Malaria Foundation,Machine Intelligence Research Institute,The Good Food Institute,StrongMinds','Reasoning supplement',NULL,'Version 0 of a decision process for what charity to grant 10,000 UK pouds to. Result was a tie between Machine Intelligence Research Institute and StrongMinds. See http://effective-altruism.com/ea/187/oxford_prioritisation_project_version_0/ for a cross-post with comments'),
  ('https://oxpr.io/blog/2017/2/28/daniel-may-current-view-machine-intelligence-research-institute','Daniel May: current view, Machine Intelligence Research Institute','2017-02-15',NULL,'Daniel May','Oxford Prioritisation Project','Oxford Prioritisation Project','Machine Intelligence Research Institute','Evaluator review of donee','AI risk','Daniel May evaluates the Machine Intelligence Research Institute and describes his reasons for considering it the best donation opportunity'),
  ('https://oxpr.io/blog/2017/2/28/lovisa-tengberg-current-view-strongminds','Lovisa Tengberg: current view, StrongMinds','2017-02-14',NULL,'Lovisa Tengberg','Oxford Prioritisation Project','Oxford Prioritisation Project','StrongMinds,Against Malaria Foundation','Evaluator review of donee','Mental health','Lovisa Tengberg evaluates StrongMinds and argues that it could be the best donation opportunities. Other candidates mentioned, all in the area of mental health, are Alderman Foundation, AEGIS Foundation, and Network for Empowerment and Progressive Initiative');
  ('https://oxpr.io/blog/2017/2/28/konstantin-sietzy-current-view-strongminds','Konstantin Sietzy','2017-02-21',NULL,'Konstantin Sietzy','Oxford Prioritisation Project','Oxford Prioritisation Project','StrongMinds,Machine Intelligence Research Institute','Evaluator review of donee','Mental health','Konstantin Sietzy explains why StrongMinds is the best charity in his view. Also lists Machine Intelligence Research Institute as the runner-up'),
  ('https://oxpr.io/blog/2017/2/11/tom-sittler-assumptions-of-arguments-for-existential-risk-reduction','Tom Sittler: Assumptions of arguments for existential risk reduction','2017-01-27','2017-02-10','Tom Sittler','Oxford Prioritisation Project','Oxford Prioritisation Project',NULL,'Review of current state of cause area','AI risk','The abstract reads: "I review an informal argument for existential risk reduction as the top priority. I argue the informal argument, or at least some renditions of it, are vulnerable to two objections: (i) The far future may not be good, and we are making predictions based on very weak evidence when we estimate whether it will be good (ii) reductions in existential risk over the next century are much less valuable than equivalent increases in the probability that humanity will have a very long future."'),
  ('https://oxpr.io/blog/2017/2/13/crispr-biorisk-as-an-oxford-prioritisation-project-topic','Laurie Pycroft: "CRISPR biorisk as an Oxford Prioritisation Project topic"','2017-02-13',NULL,'Laurie Pycroft','Oxford Prioritisation Project','Oxford Prioritisation Project',NULL,'Review of current state of cause area','Biosecurity and pandemic preparedness','The article explores CRISPR biorisk as a potential funding opportunity for the Oxford Prioritisation Project'),
  ('https://oxpr.io/blog/2017/2/13/another-brick-in-the-wall','Another brick in the wall?','2017-02-13',NULL,'Tom Sittler,Konstantin Sietzy,Jacob Lagerros','Oxford Prioritisation Project','Oxford Prioritisation Project',NULL,'Broad donor strategy',NULL,'The summary begins: "Should the Oxford Prioritisation Project focus on donation opportunities that are ‘the right size’? Is it important to find a £10,000 funding gap for a specific purchase, (or by way of analogy, £10,000-shaped lego bricks)?" The conclusion is that Lego bricks are unlikely to be relevant'),
  ('https://oxpr.io/blog/2017/2/10/sindy-li-does-research-into-neglected-tropical-diseases-dominate-givewell-top-interventions',
